{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "45Itua7izpw0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"merged_tickets_with_weather.csv\")"
      ],
      "metadata": {
        "id": "Wi1mXQYwzxvX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9pX5AfXL0Ak6",
        "outputId": "50fffa95-2175-4a08-f007-56a3182e9b28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def clean_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "text_columns = ['Origin', 'Airline', 'Flight Type', 'Price Type', 'Season', 'Rain']\n",
        "for col in text_columns:\n",
        "    df[col] = df[col].apply(clean_text)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6fN8m4lV5JdW",
        "outputId": "57136d36-b42e-482c-f33c-7b2588230bba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Departure      Return     Airline Duration  Transit   Price  \\\n",
            "0  2025-04-02  2025-04-09  air france  17h 30m        1  1393.0   \n",
            "1  2025-04-02  2025-04-09  air france  20h 25m        1   992.0   \n",
            "2  2025-04-02  2025-04-09  air france  35h 05m        1  1513.0   \n",
            "3  2025-04-02  2025-04-09  air france  36h 20m        1  1151.0   \n",
            "4  2025-04-02  2025-04-09  air france  17h 30m        1  1114.0   \n",
            "\n",
            "   Competitor Price  Duration in Minutes Flight Type  Price Type  Season  \\\n",
            "0           1435.84                 1050       short  affordable  spring   \n",
            "1           1034.84                 1225      medium  affordable  spring   \n",
            "2           1555.84                 2105        long   expensive  spring   \n",
            "3           1193.84                 2180        long  affordable  spring   \n",
            "4           1156.84                 1050       short  affordable  spring   \n",
            "\n",
            "   Price per Hour Origin  Average Temp (Â°C)  Precipitation (mm) Rain  \n",
            "0           79.60     la               13.6                 0.2  yes  \n",
            "1           48.59     la               13.6                 0.2  yes  \n",
            "2           43.13     la               13.6                 0.2  yes  \n",
            "3           31.68     la               13.6                 0.2  yes  \n",
            "4           63.66     la               13.6                 0.2  yes  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned']=df['Origin']+' '+df['Airline']+' '+df['Flight Type']+' '+df['Price Type']+' '+df['Season']+' '+df['Rain']"
      ],
      "metadata": {
        "id": "I4eN7XVP7BiS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf.fit_transform(df['cleaned'])\n",
        "\n",
        "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
        "word_scores = tfidf_df.sum().sort_values(ascending=False)\n",
        "\n",
        "top_keywords = word_scores.head(10)\n",
        "print(top_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-QUkNIJ67S3",
        "outputId": "3e126d38-a87c-46d0-ca36-87be35b40231"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes           1074.396321\n",
            "affordable    1059.457979\n",
            "short          929.533569\n",
            "medium         926.896783\n",
            "riyadh         897.149558\n",
            "autumn         892.737590\n",
            "paris          879.895190\n",
            "mea            854.845419\n",
            "summer         827.531452\n",
            "airline        791.246885\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm # english model\n",
        "!pip install textblob #sentiment analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9jHQYmy8GbW",
        "outputId": "3170aaf2-a77a-44a7-fa73-60e8aca49d5c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâ  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "sample_titles = df['cleaned'].sample(10, random_state=1).tolist()\n",
        "\n",
        "for title in sample_titles:\n",
        "    doc = nlp(title)\n",
        "    print(f\"Title: {title}\")\n",
        "    for token in doc:\n",
        "        print(f\"{token.text} - {token.pos_}\")\n",
        "    print(\"--------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd1WO1Rj8KNu",
        "outputId": "5764b844-21be-443f-f45b-1804d31ce38d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: riyadh etihad airway long affordable autumn yes\n",
            "riyadh - PROPN\n",
            "etihad - VERB\n",
            "airway - VERB\n",
            "long - ADV\n",
            "affordable - ADJ\n",
            "autumn - NOUN\n",
            "yes - INTJ\n",
            "--------------\n",
            "Title: la air france long affordable autumn \n",
            "la - ADP\n",
            "air - PROPN\n",
            "france - PROPN\n",
            "long - PROPN\n",
            "affordable - ADJ\n",
            "autumn - NOUN\n",
            "--------------\n",
            "Title: paris mea short cheap autumn yes\n",
            "paris - PROPN\n",
            "mea - PROPN\n",
            "short - PROPN\n",
            "cheap - PROPN\n",
            "autumn - NOUN\n",
            "yes - INTJ\n",
            "--------------\n",
            "Title: la turkish airline short affordable winter yes\n",
            "la - INTJ\n",
            "turkish - VERB\n",
            "airline - NOUN\n",
            "short - ADJ\n",
            "affordable - ADJ\n",
            "winter - NOUN\n",
            "yes - INTJ\n",
            "--------------\n",
            "Title: riyadh qatar airway medium cheap autumn \n",
            "riyadh - PROPN\n",
            "qatar - PROPN\n",
            "airway - NOUN\n",
            "medium - NOUN\n",
            "cheap - ADJ\n",
            "autumn - NOUN\n",
            "--------------\n",
            "Title: la turkish airline medium affordable summer \n",
            "la - INTJ\n",
            "turkish - VERB\n",
            "airline - NOUN\n",
            "medium - NOUN\n",
            "affordable - ADJ\n",
            "summer - NOUN\n",
            "--------------\n",
            "Title: riyadh qatar airway medium cheap autumn \n",
            "riyadh - PROPN\n",
            "qatar - PROPN\n",
            "airway - NOUN\n",
            "medium - NOUN\n",
            "cheap - ADJ\n",
            "autumn - NOUN\n",
            "--------------\n",
            "Title: paris turkish airline medium expensive winter yes\n",
            "paris - PROPN\n",
            "turkish - VERB\n",
            "airline - NOUN\n",
            "medium - NOUN\n",
            "expensive - ADJ\n",
            "winter - NOUN\n",
            "yes - INTJ\n",
            "--------------\n",
            "Title: paris mea short expensive summer yes\n",
            "paris - PROPN\n",
            "mea - PROPN\n",
            "short - PROPN\n",
            "expensive - ADJ\n",
            "summer - NOUN\n",
            "yes - INTJ\n",
            "--------------\n",
            "Title: riyadh mea short affordable summer \n",
            "riyadh - PROPN\n",
            "mea - PROPN\n",
            "short - ADJ\n",
            "affordable - ADJ\n",
            "summer - NOUN\n",
            "--------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X = vectorizer.fit_transform(df['cleaned'])\n",
        "\n",
        "kmeans = KMeans(n_clusters=4, random_state=42, n_init='auto')\n",
        "kmeans.fit(X)\n",
        "df['cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "4-BwF7gu8ZL6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms = vectorizer.get_feature_names_out()\n",
        "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
        "\n",
        "print(\"Top 5 words per cluster:\\n\")\n",
        "for i in range(4):\n",
        "    print(f\"Cluster {i}:\")\n",
        "    top_words = [terms[ind] for ind in order_centroids[i, :5]]\n",
        "    print(\", \".join(top_words))\n",
        "    print(\"--------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1twYzZro8ZIf",
        "outputId": "274a00d9-c898-4649-d14c-010f109d0dc5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 words per cluster:\n",
            "\n",
            "Cluster 0:\n",
            "paris, short, mea, yes, affordable\n",
            "--------\n",
            "Cluster 1:\n",
            "airway, qatar, riyadh, medium, affordable\n",
            "--------\n",
            "Cluster 2:\n",
            "airline, turkish, la, medium, yes\n",
            "--------\n",
            "Cluster 3:\n",
            "riyadh, mea, short, affordable, autumn\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "tfidf_matrix = vectorizer.fit_transform(df['cleaned'])\n",
        "\n",
        "def search_products(query, top_n=3):\n",
        "    query_vec = vectorizer.transform([query])\n",
        "    similarity_scores = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
        "    top_indices = similarity_scores.argsort()[::-1][:top_n]\n",
        "    results = df.iloc[top_indices][['Price','Departure','Return','Season','Airline']]\n",
        "    return results\n",
        "\n",
        "location = input(\"Enter the location: \")\n",
        "season = input(\"Enter the season: \")\n",
        "query = location + ' ' + season\n",
        "results = search_products(query)\n",
        "print(\"Top 3 matching product titles:\")\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9z5GnLY8i8K",
        "outputId": "6068b8b5-1a72-4217-ef60-14124352b0bf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the location: riyad\n",
            "Enter the season: Fall\n",
            "Top 3 matching product titles:\n",
            "     Price   Departure      Return  Season          Airline\n",
            "16  1163.0  2025-04-02  2025-04-09  spring  turkish airline\n",
            "17  1127.0  2025-04-02  2025-04-09  spring     qatar airway\n",
            "18  1327.0  2025-04-02  2025-04-09  spring     qatar airway\n"
          ]
        }
      ]
    }
  ]
}